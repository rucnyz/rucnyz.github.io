---
---

@string{aps = {American Physical Society,}}

@book{CICAI_AIMI,
  bibtex_show={false},
  title={Adversarial and Implicit Modality Imputation with Applications to Depression Early Detection},
  author={Yuzhou Nie*, Chengyue Huang*, Hailun Liang, Hongteng Xu},
  year={2022},
  pdf={AIMI_CICAI.pdf},
  code={https://github.com/rucnyz/AIMI},
  abbr={CICAI},
  selected={true},
  abstract={Depression early detection is a significant healthcare task that heavily relies on high-quality multi-modal medical data. In practice, however, learning a robust detection model is challenging because real-world data often suffers from serious modality-level missing issues caused by imperfect data collection and strict data sharing policies. In this study, we propose an Adversarial and Implicit Modality Imputation (AIMI) method to resolve this challenge. In particular, when training multi-modal predictive models, we learn an implicit mechanism to impute the missing modalities of training data at the same time. These two learning objectives are achieved jointly in an adversarial learning framework. Based on the UK Biobank dataset, we demonstrate the effectiveness and superiority of our method on the early detection of depression. Codes are available at https://github.com/rucnyz/AIMI}
}

@article{GWMAC_CIKM,
  abbr={CIKM},
  author={Gong*, Fengjiao and Nie*, Yuzhou and Xu, Hongteng},
  title={Gromov-Wasserstein Multi-Modal Alignment and Clustering},
  year={2022},
  isbn={9781450392365},
  publisher={Association for Computing Machinery},
  address={New York, NY, USA},
  url={https://doi.org/10.1145/3511808.3557339},
  doi={10.1145/3511808.3557339},
  abstract={Multi-modal clustering aims at finding a clustering structure shared by the data of different modalities in an unsupervised way. Currently, solving this problem often relies on two assumptions: i) the multi-modal data own the same latent distribution, and ii) the observed multi-modal data are well-aligned and without any missing modalities. Unfortunately, these two assumptions are often questionable in practice and thus limit the feasibility of many multi-modal clustering methods. In this work, we develop a new multi-modal clustering method based on the Gromovization of optimal transport distance, which relaxes the dependence on the above two assumptions. In particular, given the data of different modalities, whose correspondence is unknown, our method learns the Gromov-Wasserstein (GW) barycenter of their kernel matrices. Driven by the modularity maximization principle, the GW barycenter helps to explore the clustering structure shared by different modalities. Moreover, the GW barycenter is associated with the GW distances between the different modalities to the clusters, and the optimal transport plans corresponding to the GW distances help to achieve the alignment and the clustering of the multi-modal data jointly. Experimental results show that our method outperforms state-of-the-art multi-modal clustering methods, especially when the data are (partially or completely) unaligned. The code is available at https://github.com/rucnyz/GWMAC.},
  booktitle={Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management},
  pages={603â€“613},
  numpages={11},
  keywords={gromov-wasserstein barycenter, optimal transport, data alignment, multi-modal clustering, kernel fusion},
  location={Atlanta, GA, USA},
  series={CIKM '22},
  selected={true},
  pdf={GWMAC_CIKM2022.pdf},
  code={https://github.com/rucnyz/GWMAC},
  bibtex_show={true},
}

